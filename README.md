# Gender Bias Detection

The concept of bias in machine learning models refers to the tendency of the model to favor certain outcomes over others. This study focuses on two types of biases: gender and racial bias. To investigate gender bias, we utilized Bert models, which employ attention and masking mechanisms. We fed these models with various job titles in both Persian and English, and then calculated the weight assigned to each gender. For examining both gender and racial biases across different languages, we employed the XLM-RoBERTa model, which uses a masked language model (MLM). After the initial analysis, we scored the models based on their performance. The next step involved efforts to improve these models through creation and fine-tuning. Finally, we reassessed the models post-modification to evaluate the effectiveness of the changes implemented.
